I have been able to obtain the number of different types of anomalies (classifier.py). The key to this is in the decision path.
Next I wanted to add some explainability. So, for example, given a certain anomalous windows and the RF model, I would like
to obtain the variables and their thresholds that define the anomalie as anomalous in the structure of the trees that make
the RF model.

In classifier copy.py I did changes on line 48 {anomaly_indices = [0]} and the last for loop to only save the decision paths
of the first anomalous window. Then on test.py I loaded the model and the saved decision_paths.npy object and selected
the decision_path of the first anomaly (although this seems redundant because ther should be only one decision_path saved)
Then I extracted the indices of the of the nodes passed by that anomaly and used those indices to get the feature names and 
their thresholds.

In summary, I am only working with the first anomalous window on the first tree thanks to the changes on classifier copy.
Now I need to upscale this idea to work with the first anomaly (for example) across all decision trees of the RF, and
get the thresholds and features of the nodes this anomaly travels through. Then, maybe by extracting the most repeated ones
I could be able to give an explanation for the anomaly.

The goal is, given an anomaly -> explain what variables are the ones that define it. Then maybe say in what cluster it is
but that is easy, given the index just access integer_decision_paths.
